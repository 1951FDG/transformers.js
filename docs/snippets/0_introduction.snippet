
<p align="center">
    <a href="https://www.npmjs.com/package/@xenova/transformers">
        <img alt="NPM" src="https://img.shields.io/npm/v/@xenova/transformers">
    </a>
    <a href="https://www.npmjs.com/package/@xenova/transformers">
        <img alt="Downloads" src="https://img.shields.io/npm/dw/@xenova/transformers">
    </a>
    <a href="https://github.com/xenova/transformers.js/blob/main/LICENSE">
        <img alt="License" src="https://img.shields.io/github/license/xenova/transformers.js">
    </a>
    <a href="https://huggingface.co/docs/transformers.js/index">
        <img alt="Documentation" src="https://img.shields.io/website/http/huggingface.co/docs/transformers.js/index.svg?down_color=red&down_message=offline&up_message=online">
    </a>
</p>


State-of-the-art Machine Learning for the web. Run 🤗 Transformers directly in your browser, with no need for a server!

Transformers.js is designed to be functionally equivalent to Hugging Face's [transformers](https://github.com/huggingface/transformers) python library, meaning you can run the same pretrained models using a very similar API. These models support common tasks in different modalities, such as:
  - 📝 **Natural Language Processing**: text classification, named entity recognition, question answering, language modeling, summarization, translation, multiple choice, and text generation.
  - 🖼️ **Computer Vision**: image classification, object detection, and segmentation.
  - 🗣️ **Audio**: automatic speech recognition and audio classification.
  - 🐙 **Multimodal**: zero-shot image classification.

Transformers.js uses [ONNX Runtime](https://onnxruntime.ai/) to run models in the browser. The best part about it, is that you can easily [convert](/custom_usage#convert-your-models-to-onnx) your pretrained PyTorch, TensorFlow, or JAX models to ONNX using [🤗 Optimum](https://github.com/huggingface/optimum#onnx--onnx-runtime). 

For more information, check out the full [documentation](https://huggingface.co/docs/transformers.js).
